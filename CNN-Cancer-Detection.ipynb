{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cffb9884",
   "metadata": {},
   "source": [
    "# Cancer Detection\n",
    "\n",
    "The problem is whether deep learning using a convolutional neural network can be used to detect cancer in histopathologic images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "56252701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "52291ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 96\n",
    "IMAGE_CHANNELS = 3\n",
    "SAMPLE_SIZE = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "172028a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv', 'test', 'train', 'train_labels.csv']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "os.listdir(os.path.join(BASE_DIR, 'input'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1a55ec",
   "metadata": {},
   "source": [
    "## Dataset Information\n",
    "\n",
    "How many train/test images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9bf05f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: 220026\n",
      "Test images: 57458\n"
     ]
    }
   ],
   "source": [
    "num_train = len(os.listdir(os.path.join(BASE_DIR, 'input\\\\train')))\n",
    "num_test = len(os.listdir(os.path.join(BASE_DIR, 'input\\\\test')))\n",
    "print(f\"Train images: {num_train}\")\n",
    "print(f\"Test images: {num_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c0df2d",
   "metadata": {},
   "source": [
    "Import labels into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "160baee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                               id  label\n",
       "0       f38a6374c348f90b587e046aac6079959adf3835      0\n",
       "1       c18f2d887b7ae4f6742ee445113fa1aef383ed77      1\n",
       "2       755db6279dae599ebb4d39a9123cce439965282d      0\n",
       "3       bc3f0c64fb968ff4a8bd33af6971ecae77c75e08      0\n",
       "4       068aba587a4950175d04c680d38943fd488d6a9d      0\n",
       "...                                          ...    ...\n",
       "220020  53e9aa9d46e720bf3c6a7528d1fca3ba6e2e49f6      0\n",
       "220021  d4b854fe38b07fe2831ad73892b3cec877689576      1\n",
       "220022  3d046cead1a2a5cbe00b2b4847cfb7ba7cf5fe75      0\n",
       "220023  f129691c13433f66e1e0671ff1fe80944816f5a2      0\n",
       "220024  a81f84895ddcd522302ddf34be02eb1b3e5af1cb      1\n",
       "\n",
       "[220025 rows x 2 columns]>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(BASE_DIR, 'input\\\\train_labels.csv'))\n",
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bf4516",
   "metadata": {},
   "source": [
    "Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a42087ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['label'].value_counts()\n",
    "plt.bar([\"Negative\", \"Positive\"], height=df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b763e50f",
   "metadata": {},
   "source": [
    "Rather than use the whole dataset, let's sample 40,000 of each label and then create balanced train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "408514e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64000, 2)\n",
      "(16000, 2)\n",
      "1    32000\n",
      "0    32000\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_0 = df[df['label'] == 0].sample(SAMPLE_SIZE, random_state=123)\n",
    "df_1 = df[df['label'] == 1].sample(SAMPLE_SIZE, random_state=123)\n",
    "\n",
    "sampled_df = pd.concat([df_0, df_1], axis=0).reset_index(drop=True)\n",
    "sampled_df = shuffle(sampled_df)\n",
    "sampled_df['label'].value_counts()\n",
    "\n",
    "# stratify to create balanced set\n",
    "df_train, df_val = train_test_split(sampled_df, test_size=0.20, random_state=123, stratify=sampled_df['label'])\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)\n",
    "print(df_train['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cac643",
   "metadata": {},
   "source": [
    "Put images of the sampled IDs into a folder structure for the generator to use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9ecd3aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df_train.iterrows():\n",
    "    fname = row['id'] + '.tif'\n",
    "    label = \"no_tumor\" if row['label'] == 0 else \"has_tumor\"\n",
    "    \n",
    "    src = os.path.join(BASE_DIR, 'input//train', fname)\n",
    "    dest = os.path.join(BASE_DIR, 'sampled//train', label, fname)\n",
    "    \n",
    "    shutil.copyfile(src, dest)\n",
    "\n",
    "for idx, row in df_val.iterrows():\n",
    "    fname = row['id'] + '.tif'\n",
    "    label = \"no_tumor\" if row['label'] == 0 else \"has_tumor\"\n",
    "    \n",
    "    src = os.path.join(BASE_DIR, 'input//train', fname)\n",
    "    dest = os.path.join(BASE_DIR, 'sampled//valid', label, fname)\n",
    "    \n",
    "    shutil.copyfile(src, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "8859190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(BASE_DIR, 'sampled//train')\n",
    "valid_path = os.path.join(BASE_DIR, 'sampled//valid')\n",
    "test_path = os.path.join(BASE_DIR, 'input//competition')\n",
    "\n",
    "num_train_samples = len(df_train)\n",
    "num_val_samples = len(df_val)\n",
    "train_batch_size = 32\n",
    "val_batch_size = 32\n",
    "\n",
    "\n",
    "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples / val_batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "4a9c55d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n",
      "Found 57458 images belonging to 1 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'has_tumor': 0, 'no_tumor': 1}"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(train_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=train_batch_size,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "val_gen = datagen.flow_from_directory(valid_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=val_batch_size,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "test_gen = datagen.flow_from_directory(valid_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=1,\n",
    "                                        class_mode='categorical',\n",
    "                                        shuffle=False)\n",
    "\n",
    "competition_gen = datagen.flow_from_directory(test_path,\n",
    "                                              target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                              batch_size = 1,\n",
    "                                              class_mode=None,\n",
    "                                              shuffle=False\n",
    "                                             )\n",
    "test_gen.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dc6f22",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "## Base Model\n",
    "Let's train a base model. Parameters are taken from https://www.tensorflow.org/tutorials/load_data/images with the addition of softmax in the final layer. Let's save the best epoch and use an adaptive learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "5444a36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, loss, accuracy]\n",
       "Index: []"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=('model', 'loss', 'accuracy'))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "146e663b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_90 (Conv2D)           (None, 94, 94, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 45, 45, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 20, 20, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 128)               409728    \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 429,378\n",
      "Trainable params: 429,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "\n",
    "model1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape = (96, 96, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "34b83000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2000/2000 [==============================] - 34s 16ms/step - loss: 0.4912 - accuracy: 0.7695 - val_loss: 0.4604 - val_accuracy: 0.7907\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.79069, saving model to model1.h5\n",
      "Epoch 2/15\n",
      "2000/2000 [==============================] - 31s 15ms/step - loss: 0.4582 - accuracy: 0.7880 - val_loss: 0.4450 - val_accuracy: 0.8005\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.79069 to 0.80050, saving model to model1.h5\n",
      "Epoch 3/15\n",
      "2000/2000 [==============================] - 29s 14ms/step - loss: 0.4341 - accuracy: 0.8007 - val_loss: 0.4176 - val_accuracy: 0.8146\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.80050 to 0.81456, saving model to model1.h5\n",
      "Epoch 4/15\n",
      "2000/2000 [==============================] - 29s 14ms/step - loss: 0.4162 - accuracy: 0.8130 - val_loss: 0.4071 - val_accuracy: 0.8210\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.81456 to 0.82100, saving model to model1.h5\n",
      "Epoch 5/15\n",
      "2000/2000 [==============================] - 29s 15ms/step - loss: 0.3950 - accuracy: 0.8252 - val_loss: 0.3933 - val_accuracy: 0.8282\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.82100 to 0.82825, saving model to model1.h5\n",
      "Epoch 6/15\n",
      "2000/2000 [==============================] - 29s 15ms/step - loss: 0.3784 - accuracy: 0.8329 - val_loss: 0.3834 - val_accuracy: 0.8349\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.82825 to 0.83494, saving model to model1.h5\n",
      "Epoch 7/15\n",
      "2000/2000 [==============================] - 30s 15ms/step - loss: 0.3625 - accuracy: 0.8412 - val_loss: 0.3700 - val_accuracy: 0.8411\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.83494 to 0.84106, saving model to model1.h5\n",
      "Epoch 8/15\n",
      "2000/2000 [==============================] - 30s 15ms/step - loss: 0.3517 - accuracy: 0.8475 - val_loss: 0.3674 - val_accuracy: 0.8407\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.84106\n",
      "Epoch 9/15\n",
      "2000/2000 [==============================] - 29s 15ms/step - loss: 0.3394 - accuracy: 0.8526 - val_loss: 0.3538 - val_accuracy: 0.8487\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.84106 to 0.84869, saving model to model1.h5\n",
      "Epoch 10/15\n",
      "2000/2000 [==============================] - 29s 15ms/step - loss: 0.3275 - accuracy: 0.8584 - val_loss: 0.3444 - val_accuracy: 0.8522\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.84869 to 0.85219, saving model to model1.h5\n",
      "Epoch 11/15\n",
      "2000/2000 [==============================] - 29s 15ms/step - loss: 0.3191 - accuracy: 0.8630 - val_loss: 0.3465 - val_accuracy: 0.8487\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.85219\n",
      "Epoch 12/15\n",
      "2000/2000 [==============================] - 29s 15ms/step - loss: 0.3105 - accuracy: 0.8675 - val_loss: 0.3359 - val_accuracy: 0.8597\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.85219 to 0.85975, saving model to model1.h5\n",
      "Epoch 13/15\n",
      "2000/2000 [==============================] - 29s 15ms/step - loss: 0.3021 - accuracy: 0.8716 - val_loss: 0.3621 - val_accuracy: 0.8478\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.85975\n",
      "Epoch 14/15\n",
      "2000/2000 [==============================] - 31s 15ms/step - loss: 0.2930 - accuracy: 0.8762 - val_loss: 0.3306 - val_accuracy: 0.8615\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.85975 to 0.86150, saving model to model1.h5\n",
      "Epoch 15/15\n",
      "2000/2000 [==============================] - 29s 15ms/step - loss: 0.2837 - accuracy: 0.8812 - val_loss: 0.3192 - val_accuracy: 0.8670\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.86150 to 0.86700, saving model to model1.h5\n"
     ]
    }
   ],
   "source": [
    "model1.compile(Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model1.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2, verbose=1, mode='max', min_lr=0.00001)\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_lr]\n",
    "\n",
    "history1 = model1.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=15,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "16801cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 23s 1ms/step - loss: 0.3192 - accuracy: 0.8670\n",
      "Test loss: 0.319\n",
      "Test accuracy: 0.867\n"
     ]
    }
   ],
   "source": [
    "model1.load_weights('model1.h5')\n",
    "\n",
    "loss1, accuracy1 = model1.evaluate(test_gen)\n",
    "\n",
    "print(f\"Test loss: {loss1:.3f}\")\n",
    "print(f\"Test accuracy: {accuracy1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "8f09e4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td>0.319171</td>\n",
       "      <td>0.867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model      loss  accuracy\n",
       "0  base  0.319171     0.867"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=('model', 'loss', 'accuracy'))\n",
    "results.loc[0] = ['base', loss1, accuracy1]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4055f7",
   "metadata": {},
   "source": [
    "The best epoch from the base model had a test accuracy of 0.87.\n",
    "\n",
    "Let's try adding regularization (dropout), which prevents overfitting.\n",
    "\n",
    "## Regularization Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "55066dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_93 (Conv2D)           (None, 94, 94, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 45, 45, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 20, 20, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 128)               409728    \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 429,378\n",
      "Trainable params: 429,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dropout_conv = 0.3\n",
    "dropout_dense = 0.3\n",
    "\n",
    "model2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape = (96, 96, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(dropout_conv),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(dropout_conv),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(dropout_conv),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(dropout_dense),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "edc3bf44",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2000/2000 [==============================] - 31s 15ms/step - loss: 0.5257 - accuracy: 0.7387 - val_loss: 0.5509 - val_accuracy: 0.7321\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.73212, saving model to model2.h5\n",
      "Epoch 2/15\n",
      "2000/2000 [==============================] - 30s 15ms/step - loss: 0.4736 - accuracy: 0.7836 - val_loss: 0.5073 - val_accuracy: 0.7641\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.73212 to 0.76406, saving model to model2.h5\n",
      "Epoch 3/15\n",
      "2000/2000 [==============================] - 29s 14ms/step - loss: 0.4545 - accuracy: 0.7932 - val_loss: 0.4830 - val_accuracy: 0.7738\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.76406 to 0.77381, saving model to model2.h5\n",
      "Epoch 4/15\n",
      "2000/2000 [==============================] - 30s 15ms/step - loss: 0.4377 - accuracy: 0.8039 - val_loss: 0.4829 - val_accuracy: 0.7756\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.77381 to 0.77562, saving model to model2.h5\n",
      "Epoch 5/15\n",
      "2000/2000 [==============================] - 30s 15ms/step - loss: 0.4284 - accuracy: 0.8080 - val_loss: 0.4747 - val_accuracy: 0.7886\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.77562 to 0.78863, saving model to model2.h5\n",
      "Epoch 6/15\n",
      "2000/2000 [==============================] - 30s 15ms/step - loss: 0.4173 - accuracy: 0.8124 - val_loss: 0.5331 - val_accuracy: 0.7279\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.78863\n",
      "Epoch 7/15\n",
      "2000/2000 [==============================] - 30s 15ms/step - loss: 0.4051 - accuracy: 0.8206 - val_loss: 0.4972 - val_accuracy: 0.7556\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.78863\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 8/15\n",
      "2000/2000 [==============================] - 30s 15ms/step - loss: 0.3882 - accuracy: 0.8297 - val_loss: 0.4965 - val_accuracy: 0.7535\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.78863\n",
      "Epoch 9/15\n",
      "2000/2000 [==============================] - 29s 15ms/step - loss: 0.3800 - accuracy: 0.8338 - val_loss: 0.4948 - val_accuracy: 0.7608\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.78863\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 10/15\n",
      "2000/2000 [==============================] - 29s 15ms/step - loss: 0.3717 - accuracy: 0.8385 - val_loss: 0.5112 - val_accuracy: 0.7499\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.78863\n",
      "Epoch 11/15\n",
      "2000/2000 [==============================] - 30s 15ms/step - loss: 0.3677 - accuracy: 0.8403 - val_loss: 0.5186 - val_accuracy: 0.7455\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.78863\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 12/15\n",
      "2000/2000 [==============================] - 31s 16ms/step - loss: 0.3638 - accuracy: 0.8420 - val_loss: 0.4834 - val_accuracy: 0.7669\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.78863\n",
      "Epoch 13/15\n",
      "2000/2000 [==============================] - 29s 14ms/step - loss: 0.3629 - accuracy: 0.8419 - val_loss: 0.5164 - val_accuracy: 0.7454\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.78863\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 14/15\n",
      "2000/2000 [==============================] - 29s 15ms/step - loss: 0.3599 - accuracy: 0.8431 - val_loss: 0.5069 - val_accuracy: 0.7531\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.78863\n",
      "Epoch 15/15\n",
      "2000/2000 [==============================] - 29s 14ms/step - loss: 0.3592 - accuracy: 0.8438 - val_loss: 0.5195 - val_accuracy: 0.7414\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.78863\n"
     ]
    }
   ],
   "source": [
    "model2.compile(Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model2.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2, verbose=1, mode='max', min_lr=0.00001)\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_lr]\n",
    "\n",
    "history2 = model2.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=15,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "94489fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 21s 1ms/step - loss: 0.4747 - accuracy: 0.7886\n",
      "Test loss: 0.475\n",
      "Test accuracy: 0.789\n"
     ]
    }
   ],
   "source": [
    "model2.load_weights('model2.h5')\n",
    "\n",
    "loss, accuracy = model2.evaluate(test_gen)\n",
    "\n",
    "print(f\"Test loss: {loss:.3f}\")\n",
    "print(f\"Test accuracy: {accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f493426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[1] = ['dropout', loss, accuracy]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c824819b",
   "metadata": {},
   "source": [
    "Adding regularization lowered the accuracy to 0.79, suggesting that it was overfitting before.\n",
    "\n",
    "## Increasing Filter Sizes\n",
    "\n",
    "Let's try having increasing convolutional filters (32, 64 & 128). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "54a81eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_99 (Conv2D)           (None, 94, 94, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_66 (MaxPooling (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 45, 45, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_67 (MaxPooling (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_101 (Conv2D)          (None, 20, 20, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_68 (MaxPooling (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 128)               1638528   \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 1,732,034\n",
      "Trainable params: 1,732,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dropout_conv = 0.3\n",
    "dropout_dense = 0.3\n",
    "\n",
    "model3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape = (96, 96, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(dropout_conv),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(dropout_conv),\n",
    "    tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(dropout_conv),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(dropout_dense),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b388f75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2000/2000 [==============================] - 31s 15ms/step - loss: 0.5273 - accuracy: 0.7398 - val_loss: 0.5117 - val_accuracy: 0.7864\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78637, saving model to model3.h5\n",
      "Epoch 2/15\n",
      "2000/2000 [==============================] - 29s 15ms/step - loss: 0.4681 - accuracy: 0.7859 - val_loss: 0.4810 - val_accuracy: 0.7843\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.78637\n",
      "Epoch 3/15\n",
      "2000/2000 [==============================] - 29s 14ms/step - loss: 0.4492 - accuracy: 0.7968 - val_loss: 0.4531 - val_accuracy: 0.8117\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.78637 to 0.81169, saving model to model3.h5\n",
      "Epoch 4/15\n",
      "2000/2000 [==============================] - 29s 15ms/step - loss: 0.4274 - accuracy: 0.8082 - val_loss: 0.4493 - val_accuracy: 0.7989\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.81169\n",
      "Epoch 5/15\n",
      "2000/2000 [==============================] - 29s 14ms/step - loss: 0.4049 - accuracy: 0.8188 - val_loss: 0.4453 - val_accuracy: 0.7936\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.81169\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 6/15\n",
      "2000/2000 [==============================] - 29s 15ms/step - loss: 0.3828 - accuracy: 0.8313 - val_loss: 0.4533 - val_accuracy: 0.7942\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.81169\n",
      "Epoch 7/15\n",
      "2000/2000 [==============================] - 29s 15ms/step - loss: 0.3709 - accuracy: 0.8383 - val_loss: 0.4248 - val_accuracy: 0.8113\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.81169\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 8/15\n",
      "2000/2000 [==============================] - 29s 15ms/step - loss: 0.3563 - accuracy: 0.8455 - val_loss: 0.4225 - val_accuracy: 0.8094\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.81169\n",
      "Epoch 9/15\n",
      "2000/2000 [==============================] - 30s 15ms/step - loss: 0.3510 - accuracy: 0.8489 - val_loss: 0.4163 - val_accuracy: 0.8127\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.81169 to 0.81269, saving model to model3.h5\n",
      "Epoch 10/15\n",
      "2000/2000 [==============================] - 30s 15ms/step - loss: 0.3476 - accuracy: 0.8504 - val_loss: 0.3859 - val_accuracy: 0.8348\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.81269 to 0.83481, saving model to model3.h5\n",
      "Epoch 11/15\n",
      "2000/2000 [==============================] - 29s 15ms/step - loss: 0.3437 - accuracy: 0.8525 - val_loss: 0.3892 - val_accuracy: 0.8318\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.83481\n",
      "Epoch 12/15\n",
      "2000/2000 [==============================] - 30s 15ms/step - loss: 0.3396 - accuracy: 0.8541 - val_loss: 0.3886 - val_accuracy: 0.8304\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.83481\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 13/15\n",
      "2000/2000 [==============================] - 30s 15ms/step - loss: 0.3338 - accuracy: 0.8573 - val_loss: 0.3817 - val_accuracy: 0.8332\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.83481\n",
      "Epoch 14/15\n",
      "2000/2000 [==============================] - 30s 15ms/step - loss: 0.3300 - accuracy: 0.8586 - val_loss: 0.3931 - val_accuracy: 0.8269\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.83481\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 15/15\n",
      "2000/2000 [==============================] - 30s 15ms/step - loss: 0.3298 - accuracy: 0.8592 - val_loss: 0.3920 - val_accuracy: 0.8253\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.83481\n"
     ]
    }
   ],
   "source": [
    "model3.compile(Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model3.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2, verbose=1, mode='max', min_lr=0.00001)\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_lr]\n",
    "\n",
    "history3 = model3.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=15,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "cbddc1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 19s 1ms/step - loss: 0.3859 - accuracy: 0.8348\n",
      "Test loss: 0.386\n",
      "Test accuracy: 0.835\n"
     ]
    }
   ],
   "source": [
    "model3.load_weights('model3.h5')\n",
    "\n",
    "loss, accuracy = model3.evaluate(test_gen)\n",
    "\n",
    "print(f\"Test loss: {loss:.3f}\")\n",
    "print(f\"Test accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "e1c29961",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[2] = ['dropout+inc_filters', loss, accuracy]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c95b22",
   "metadata": {},
   "source": [
    "Adding increasing filter sizes increased the accuracy without it overfitting\n",
    "\n",
    "## Larger Dense Layer\n",
    "\n",
    "Let's try doubling the size of the dense layer to 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b72c45be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_102 (Conv2D)          (None, 94, 94, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_69 (MaxPooling (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_103 (Conv2D)          (None, 45, 45, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_70 (MaxPooling (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_104 (Conv2D)          (None, 20, 20, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_71 (MaxPooling (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 256)               3277056   \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,370,818\n",
      "Trainable params: 3,370,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dropout_conv = 0.3\n",
    "dropout_dense = 0.3\n",
    "\n",
    "model4 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape = (96, 96, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(dropout_conv),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(dropout_conv),\n",
    "    tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(dropout_conv),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(dropout_dense),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2db5aeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2000/2000 [==============================] - 30s 15ms/step - loss: 0.5129 - accuracy: 0.7520 - val_loss: 0.5197 - val_accuracy: 0.7594\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.75937, saving model to model4.h5\n",
      "Epoch 2/15\n",
      "2000/2000 [==============================] - 30s 15ms/step - loss: 0.4628 - accuracy: 0.7870 - val_loss: 0.4827 - val_accuracy: 0.7793\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.75937 to 0.77925, saving model to model4.h5\n",
      "Epoch 3/15\n",
      "2000/2000 [==============================] - 29s 14ms/step - loss: 0.4380 - accuracy: 0.8015 - val_loss: 0.4614 - val_accuracy: 0.7934\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.77925 to 0.79344, saving model to model4.h5\n",
      "Epoch 4/15\n",
      "2000/2000 [==============================] - 29s 15ms/step - loss: 0.4157 - accuracy: 0.8140 - val_loss: 0.4971 - val_accuracy: 0.7473\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.79344\n",
      "Epoch 5/15\n",
      "2000/2000 [==============================] - 30s 15ms/step - loss: 0.3926 - accuracy: 0.8265 - val_loss: 0.5666 - val_accuracy: 0.7237\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.79344\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 6/15\n",
      "2000/2000 [==============================] - 30s 15ms/step - loss: 0.3743 - accuracy: 0.8373 - val_loss: 0.5696 - val_accuracy: 0.7111\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.79344\n",
      "Epoch 7/15\n",
      "2000/2000 [==============================] - 29s 14ms/step - loss: 0.3639 - accuracy: 0.8423 - val_loss: 0.5611 - val_accuracy: 0.7216\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.79344\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 8/15\n",
      "2000/2000 [==============================] - 29s 14ms/step - loss: 0.3531 - accuracy: 0.8470 - val_loss: 0.5712 - val_accuracy: 0.7110\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.79344\n",
      "Epoch 9/15\n",
      "2000/2000 [==============================] - 29s 15ms/step - loss: 0.3487 - accuracy: 0.8496 - val_loss: 0.5377 - val_accuracy: 0.7324\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.79344\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 10/15\n",
      "2000/2000 [==============================] - 29s 15ms/step - loss: 0.3433 - accuracy: 0.8519 - val_loss: 0.5754 - val_accuracy: 0.7128\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.79344\n",
      "Epoch 11/15\n",
      "2000/2000 [==============================] - 29s 14ms/step - loss: 0.3415 - accuracy: 0.8531 - val_loss: 0.5467 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.79344\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 12/15\n",
      "2000/2000 [==============================] - 30s 15ms/step - loss: 0.3390 - accuracy: 0.8546 - val_loss: 0.5758 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.79344\n",
      "Epoch 13/15\n",
      "2000/2000 [==============================] - 29s 14ms/step - loss: 0.3368 - accuracy: 0.8565 - val_loss: 0.5813 - val_accuracy: 0.7211\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.79344\n",
      "Epoch 14/15\n",
      "2000/2000 [==============================] - 29s 14ms/step - loss: 0.3360 - accuracy: 0.8557 - val_loss: 0.6073 - val_accuracy: 0.7021\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.79344\n",
      "Epoch 15/15\n",
      "2000/2000 [==============================] - 29s 15ms/step - loss: 0.3340 - accuracy: 0.8560 - val_loss: 0.6173 - val_accuracy: 0.6997\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.79344\n"
     ]
    }
   ],
   "source": [
    "model4.compile(Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model4.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2, verbose=1, mode='max', min_lr=0.00001)\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_lr]\n",
    "\n",
    "history4 = model4.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=15,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "b5dceb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 20s 1ms/step - loss: 0.4614 - accuracy: 0.7934\n",
      "Test loss: 0.461\n",
      "Test accuracy: 0.793\n"
     ]
    }
   ],
   "source": [
    "model4.load_weights('model4.h5')\n",
    "\n",
    "loss, accuracy = model4.evaluate(test_gen)\n",
    "\n",
    "print(f\"Test loss: {loss:.3f}\")\n",
    "print(f\"Test accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "123735f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[3] = ['dropout+inc_filters+larger_dense', loss, accuracy]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59af8fe4",
   "metadata": {},
   "source": [
    "A larger dense layer reduced the accuracy to 0.79, suggesting that a more complex architecture isn't necessarily better. \n",
    "\n",
    "# Duplicating Convolutions\n",
    "\n",
    "Let's try repeating the convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4d62a751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_105 (Conv2D)          (None, 94, 94, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_106 (Conv2D)          (None, 92, 92, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_107 (Conv2D)          (None, 90, 90, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_72 (MaxPooling (None, 45, 45, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 45, 45, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_108 (Conv2D)          (None, 43, 43, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_109 (Conv2D)          (None, 41, 41, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_110 (Conv2D)          (None, 39, 39, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_73 (MaxPooling (None, 19, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 19, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_111 (Conv2D)          (None, 17, 17, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_112 (Conv2D)          (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_113 (Conv2D)          (None, 13, 13, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_74 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 1,070,978\n",
      "Trainable params: 1,070,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dropout_conv = 0.3\n",
    "dropout_dense = 0.3\n",
    "\n",
    "model5 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape = (96, 96, 3)),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(dropout_conv),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(dropout_conv),\n",
    "    tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
    "    tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
    "    tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(dropout_conv),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(dropout_dense),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "50c94c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2000/2000 [==============================] - 36s 18ms/step - loss: 0.4965 - accuracy: 0.7617 - val_loss: 0.4834 - val_accuracy: 0.7721\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.77206, saving model to model5.h5\n",
      "Epoch 2/15\n",
      "2000/2000 [==============================] - 35s 18ms/step - loss: 0.4374 - accuracy: 0.8042 - val_loss: 0.4954 - val_accuracy: 0.7918\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.77206 to 0.79175, saving model to model5.h5\n",
      "Epoch 3/15\n",
      "2000/2000 [==============================] - 35s 17ms/step - loss: 0.3903 - accuracy: 0.8275 - val_loss: 0.4573 - val_accuracy: 0.7922\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.79175 to 0.79219, saving model to model5.h5\n",
      "Epoch 4/15\n",
      "2000/2000 [==============================] - 35s 17ms/step - loss: 0.3559 - accuracy: 0.8455 - val_loss: 0.3900 - val_accuracy: 0.8326\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.79219 to 0.83256, saving model to model5.h5\n",
      "Epoch 5/15\n",
      "2000/2000 [==============================] - 35s 18ms/step - loss: 0.3354 - accuracy: 0.8562 - val_loss: 0.4704 - val_accuracy: 0.8019\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.83256\n",
      "Epoch 6/15\n",
      "2000/2000 [==============================] - 35s 18ms/step - loss: 0.3195 - accuracy: 0.8637 - val_loss: 0.4026 - val_accuracy: 0.8371\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.83256 to 0.83713, saving model to model5.h5\n",
      "Epoch 7/15\n",
      "2000/2000 [==============================] - 35s 17ms/step - loss: 0.3040 - accuracy: 0.8714 - val_loss: 0.3094 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.83713 to 0.86606, saving model to model5.h5\n",
      "Epoch 8/15\n",
      "2000/2000 [==============================] - 37s 18ms/step - loss: 0.2912 - accuracy: 0.8770 - val_loss: 0.4509 - val_accuracy: 0.8086\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.86606\n",
      "Epoch 9/15\n",
      "2000/2000 [==============================] - 36s 18ms/step - loss: 0.2832 - accuracy: 0.8807 - val_loss: 0.3136 - val_accuracy: 0.8730\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.86606 to 0.87300, saving model to model5.h5\n",
      "Epoch 10/15\n",
      "2000/2000 [==============================] - 36s 18ms/step - loss: 0.2778 - accuracy: 0.8851 - val_loss: 0.2951 - val_accuracy: 0.8733\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.87300 to 0.87325, saving model to model5.h5\n",
      "Epoch 11/15\n",
      "2000/2000 [==============================] - 35s 18ms/step - loss: 0.2668 - accuracy: 0.8910 - val_loss: 0.3385 - val_accuracy: 0.8609\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.87325\n",
      "Epoch 12/15\n",
      "2000/2000 [==============================] - 35s 17ms/step - loss: 0.2593 - accuracy: 0.8936 - val_loss: 0.4421 - val_accuracy: 0.8183\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.87325\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 13/15\n",
      "2000/2000 [==============================] - 35s 18ms/step - loss: 0.2377 - accuracy: 0.9043 - val_loss: 0.4146 - val_accuracy: 0.8164\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.87325\n",
      "Epoch 14/15\n",
      "2000/2000 [==============================] - 36s 18ms/step - loss: 0.2317 - accuracy: 0.9072 - val_loss: 0.2400 - val_accuracy: 0.9051\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.87325 to 0.90506, saving model to model5.h5\n",
      "Epoch 15/15\n",
      "2000/2000 [==============================] - 36s 18ms/step - loss: 0.2282 - accuracy: 0.9094 - val_loss: 0.2944 - val_accuracy: 0.8759\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.90506\n"
     ]
    }
   ],
   "source": [
    "model5.compile(Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model5.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2, verbose=1, mode='max', min_lr=0.00001)\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_lr]\n",
    "\n",
    "history5 = model5.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=15,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "cafe5eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 24s 1ms/step - loss: 0.2400 - accuracy: 0.9051\n",
      "Test loss: 0.240\n",
      "Test accuracy: 0.905\n"
     ]
    }
   ],
   "source": [
    "model5.load_weights('model5.h5')\n",
    "\n",
    "loss, accuracy = model5.evaluate(test_gen)\n",
    "\n",
    "print(f\"Test loss: {loss:.3f}\")\n",
    "print(f\"Test accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "ebd0ad5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[4] = ['dropout+inc_filters+repeated_convs', loss, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "1dd673b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td>0.319171</td>\n",
       "      <td>0.867000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dropout</td>\n",
       "      <td>0.474660</td>\n",
       "      <td>0.788625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dropout+inc_filters</td>\n",
       "      <td>0.385878</td>\n",
       "      <td>0.834813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dropout+inc_filters+larger_dense</td>\n",
       "      <td>0.461351</td>\n",
       "      <td>0.793437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dropout+inc_filters+repeated_convs</td>\n",
       "      <td>0.240045</td>\n",
       "      <td>0.905062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                model      loss  accuracy\n",
       "0                                base  0.319171  0.867000\n",
       "1                             dropout  0.474660  0.788625\n",
       "2                 dropout+inc_filters  0.385878  0.834813\n",
       "3    dropout+inc_filters+larger_dense  0.461351  0.793437\n",
       "4  dropout+inc_filters+repeated_convs  0.240045  0.905062"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results.sort_index(inplace=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "f4360408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='model'>"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results.plot(x=\"model\", y=[\"accuracy\", \"loss\"], kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3384e9",
   "metadata": {},
   "source": [
    "# Hyperparmeter Tuning\n",
    "\n",
    "Now that we have a solid architecture, let's use keras tuner to tune the hyperparameters. Let's tune the dropout percentage, the number of neurons in the densely connected layer and the learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "dda5acb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    # the hyperparameters to be tuned\n",
    "    hp_dropout = hp.Choice('dropout', values=[0.2, 0.5])\n",
    "    hp_units = hp.Choice('units', values=[64, 128, 256])\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-4, 1e-5])\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape = (96, 96, 3)))\n",
    "    model.add(tf.keras.layers.Conv2D(32, 3, activation='relu'))\n",
    "    model.add(tf.keras.layers.Conv2D(32, 3, activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D())\n",
    "    model.add(tf.keras.layers.Dropout(dropout_conv))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(64, 3, activation='relu'))\n",
    "    model.add(tf.keras.layers.Conv2D(64, 3, activation='relu'))\n",
    "    model.add(tf.keras.layers.Conv2D(64, 3, activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D())\n",
    "    model.add(tf.keras.layers.Dropout(dropout_conv))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(128, 3, activation='relu'))\n",
    "    model.add(tf.keras.layers.Conv2D(128, 3, activation='relu'))\n",
    "    model.add(tf.keras.layers.Conv2D(128, 3, activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D())\n",
    "    model.add(tf.keras.layers.Dropout(dropout_conv))\n",
    "    \n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "fbece744",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18 Complete [00h 03m 47s]\n",
      "val_accuracy: 0.8261874914169312\n",
      "\n",
      "Best val_accuracy So Far: 0.8363749980926514\n",
      "Total elapsed time: 00h 26m 29s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "<keras_tuner.engine.hyperparameters.HyperParameters object at 0x0000021763033940>\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder, objective='val_accuracy', max_epochs=10)\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "tuner_callbacks_list = [stop_early]\n",
    "\n",
    "# tuner.search(img_train, label_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "tuner.search(\n",
    "    train_gen,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=15,\n",
    "    callbacks=tuner_callbacks_list\n",
    ")\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "\n",
    "# print(f\"\"\"\n",
    "# The optimal dropout_conv is {best_hps.get('dropout_conv')},\n",
    "# The optimal dropout_dense is {best_hps.get('dropout_dense')},\n",
    "# The optimal number of units in the last densely-connected layer is {best_hps.get('units')} and \n",
    "# the optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "9ab09c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\untitled_project\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x00000217631A66D0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.2\n",
      "units: 128\n",
      "learning_rate: 0.0001\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.8363749980926514\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.5\n",
      "units: 64\n",
      "learning_rate: 0.0001\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.8335000276565552\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.5\n",
      "units: 64\n",
      "learning_rate: 0.0001\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0013\n",
      "Score: 0.8261874914169312\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.2\n",
      "units: 64\n",
      "learning_rate: 0.0001\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0007\n",
      "Score: 0.8261250257492065\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.5\n",
      "units: 64\n",
      "learning_rate: 0.0001\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0005\n",
      "Score: 0.8151249885559082\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.5\n",
      "units: 256\n",
      "learning_rate: 0.0001\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0003\n",
      "Score: 0.8125625252723694\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.2\n",
      "units: 64\n",
      "learning_rate: 0.0001\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0015\n",
      "Score: 0.8121874928474426\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.5\n",
      "units: 256\n",
      "learning_rate: 0.0001\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.8113750219345093\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.2\n",
      "units: 128\n",
      "learning_rate: 0.0001\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0009\n",
      "Score: 0.8070625066757202\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.2\n",
      "units: 64\n",
      "learning_rate: 0.0001\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.8050000071525574\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a166ed3f",
   "metadata": {},
   "source": [
    "The best dropout was 0.2, the best number of densely connected neurons was 128 (which is what we began with) and the learning rate was 0.0001 (also what we began with)\n",
    "\n",
    "Let's train the hypertuned model for 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "2589d9a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 36s 18ms/step - loss: 0.4897 - accuracy: 0.7614 - val_loss: 0.4936 - val_accuracy: 0.7701\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.77006, saving model to model_hyper.h5\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 36s 18ms/step - loss: 0.4205 - accuracy: 0.8125 - val_loss: 0.4431 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.77006 to 0.79000, saving model to model_hyper.h5\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 35s 18ms/step - loss: 0.3910 - accuracy: 0.8281 - val_loss: 0.4252 - val_accuracy: 0.8004\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.79000 to 0.80037, saving model to model_hyper.h5\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 35s 18ms/step - loss: 0.3643 - accuracy: 0.8408 - val_loss: 0.4761 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.80037\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 34s 17ms/step - loss: 0.3360 - accuracy: 0.8537 - val_loss: 0.4235 - val_accuracy: 0.8093\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.80037 to 0.80931, saving model to model_hyper.h5\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 34s 17ms/step - loss: 0.3201 - accuracy: 0.8610 - val_loss: 0.4396 - val_accuracy: 0.8201\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.80931 to 0.82006, saving model to model_hyper.h5\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 34s 17ms/step - loss: 0.3025 - accuracy: 0.8708 - val_loss: 0.3325 - val_accuracy: 0.8559\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.82006 to 0.85588, saving model to model_hyper.h5\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 35s 17ms/step - loss: 0.2900 - accuracy: 0.8781 - val_loss: 0.3072 - val_accuracy: 0.8690\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.85588 to 0.86900, saving model to model_hyper.h5\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 35s 17ms/step - loss: 0.2776 - accuracy: 0.8848 - val_loss: 0.4289 - val_accuracy: 0.8133\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.86900\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 35s 17ms/step - loss: 0.2679 - accuracy: 0.8901 - val_loss: 0.3815 - val_accuracy: 0.8364\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.86900\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 35s 17ms/step - loss: 0.2452 - accuracy: 0.8993 - val_loss: 0.3431 - val_accuracy: 0.8675\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.86900\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 35s 17ms/step - loss: 0.2396 - accuracy: 0.9021 - val_loss: 0.3470 - val_accuracy: 0.8566\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.86900\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 35s 17ms/step - loss: 0.2236 - accuracy: 0.9102 - val_loss: 0.3554 - val_accuracy: 0.8605\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.86900\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 35s 17ms/step - loss: 0.2226 - accuracy: 0.9116 - val_loss: 0.4842 - val_accuracy: 0.8209\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.86900\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 35s 17ms/step - loss: 0.2125 - accuracy: 0.9143 - val_loss: 0.3479 - val_accuracy: 0.8623\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.86900\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 35s 17ms/step - loss: 0.2123 - accuracy: 0.9156 - val_loss: 0.4290 - val_accuracy: 0.8372\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.86900\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 35s 17ms/step - loss: 0.2079 - accuracy: 0.9175 - val_loss: 0.3878 - val_accuracy: 0.8468\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.86900\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 34s 17ms/step - loss: 0.2079 - accuracy: 0.9174 - val_loss: 0.3834 - val_accuracy: 0.8514\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.86900\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 34s 17ms/step - loss: 0.2064 - accuracy: 0.9181 - val_loss: 0.3309 - val_accuracy: 0.8669\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.86900\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 34s 17ms/step - loss: 0.2061 - accuracy: 0.9185 - val_loss: 0.4270 - val_accuracy: 0.8389\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.86900\n"
     ]
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model_hyper.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2, verbose=1, mode='max', min_lr=0.00001)\n",
    "\n",
    "history_hypermodel = hypermodel.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=20,\n",
    "    callbacks=[checkpoint, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "00fd6d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 23s 1ms/step - loss: 0.3072 - accuracy: 0.8690\n",
      "Test loss: 0.307\n",
      "Test accuracy: 0.869\n"
     ]
    }
   ],
   "source": [
    "hypermodel.load_weights('model_hyper.h5')\n",
    "\n",
    "loss, accuracy = hypermodel.evaluate(test_gen)\n",
    "\n",
    "print(f\"Test loss: {loss:.3f}\")\n",
    "print(f\"Test accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813354cf",
   "metadata": {},
   "source": [
    "# Predicting on the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "05c63633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57458/57458 [==============================] - 213s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = hypermodel.predict(competition_gen, steps = 57458, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "9fef82ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_tumor_tissue</th>\n",
       "      <th>no_tumor_tissue</th>\n",
       "      <th>file_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>test\\00006537328c33e284c973d7b39d340809f7271b.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999827</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>test\\0000ec92553fda4ce39889f9226ace43cae3364e.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.996456</td>\n",
       "      <td>0.003544</td>\n",
       "      <td>test\\00024a6dee61f12f7856b0fc6be20bc7a48ba3d2.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.951028</td>\n",
       "      <td>0.048972</td>\n",
       "      <td>test\\000253dfaa0be9d0d100283b22284ab2f6b643f6.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.997622</td>\n",
       "      <td>test\\000270442cc15af719583a8172c87cd2bd9c7746.tif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_tumor_tissue  no_tumor_tissue  \\\n",
       "0          0.999956         0.000043   \n",
       "1          0.999827         0.000173   \n",
       "2          0.996456         0.003544   \n",
       "3          0.951028         0.048972   \n",
       "4          0.002378         0.997622   \n",
       "\n",
       "                                          file_names  \n",
       "0  test\\00006537328c33e284c973d7b39d340809f7271b.tif  \n",
       "1  test\\0000ec92553fda4ce39889f9226ace43cae3364e.tif  \n",
       "2  test\\00024a6dee61f12f7856b0fc6be20bc7a48ba3d2.tif  \n",
       "3  test\\000253dfaa0be9d0d100283b22284ab2f6b643f6.tif  \n",
       "4  test\\000270442cc15af719583a8172c87cd2bd9c7746.tif  "
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds = pd.DataFrame(predictions, columns=['has_tumor_tissue', 'no_tumor_tissue', ])\n",
    "df_preds['file_names'] = competition_gen.filenames\n",
    "df_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "434a343a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_tumor_tissue</th>\n",
       "      <th>no_tumor_tissue</th>\n",
       "      <th>file_names</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>test\\00006537328c33e284c973d7b39d340809f7271b.tif</td>\n",
       "      <td>00006537328c33e284c973d7b39d340809f7271b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999827</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>test\\0000ec92553fda4ce39889f9226ace43cae3364e.tif</td>\n",
       "      <td>0000ec92553fda4ce39889f9226ace43cae3364e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.996456</td>\n",
       "      <td>0.003544</td>\n",
       "      <td>test\\00024a6dee61f12f7856b0fc6be20bc7a48ba3d2.tif</td>\n",
       "      <td>00024a6dee61f12f7856b0fc6be20bc7a48ba3d2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.951028</td>\n",
       "      <td>0.048972</td>\n",
       "      <td>test\\000253dfaa0be9d0d100283b22284ab2f6b643f6.tif</td>\n",
       "      <td>000253dfaa0be9d0d100283b22284ab2f6b643f6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.997622</td>\n",
       "      <td>test\\000270442cc15af719583a8172c87cd2bd9c7746.tif</td>\n",
       "      <td>000270442cc15af719583a8172c87cd2bd9c7746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_tumor_tissue  no_tumor_tissue  \\\n",
       "0          0.999956         0.000043   \n",
       "1          0.999827         0.000173   \n",
       "2          0.996456         0.003544   \n",
       "3          0.951028         0.048972   \n",
       "4          0.002378         0.997622   \n",
       "\n",
       "                                          file_names  \\\n",
       "0  test\\00006537328c33e284c973d7b39d340809f7271b.tif   \n",
       "1  test\\0000ec92553fda4ce39889f9226ace43cae3364e.tif   \n",
       "2  test\\00024a6dee61f12f7856b0fc6be20bc7a48ba3d2.tif   \n",
       "3  test\\000253dfaa0be9d0d100283b22284ab2f6b643f6.tif   \n",
       "4  test\\000270442cc15af719583a8172c87cd2bd9c7746.tif   \n",
       "\n",
       "                                         id  \n",
       "0  00006537328c33e284c973d7b39d340809f7271b  \n",
       "1  0000ec92553fda4ce39889f9226ace43cae3364e  \n",
       "2  00024a6dee61f12f7856b0fc6be20bc7a48ba3d2  \n",
       "3  000253dfaa0be9d0d100283b22284ab2f6b643f6  \n",
       "4  000270442cc15af719583a8172c87cd2bd9c7746  "
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_id(x):\n",
    "    a = x.split('\\\\')\n",
    "    b = a[1].split('.')\n",
    "    return b[0]\n",
    "\n",
    "df_preds['id'] = df_preds['file_names'].apply(get_id)\n",
    "df_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "906d88d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tumor_label(x):\n",
    "    present = 1 if x > 0.5 else 0\n",
    "    return present\n",
    "\n",
    "submission = pd.DataFrame({'id':df_preds['id'], 'label':df_preds['has_tumor_tissue'].apply(tumor_label)})\n",
    "submission.head()\n",
    "submission.to_csv('am_cancer_03.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84b1dc6",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "- Adding dropout prevented overfitting but didn't increase accuracy\n",
    "- Adding increasing filter sizes for each group of layers increased accuracy a little\n",
    "- Having more neurons in the densely connected layer didn't increase accuracy\n",
    "- Repeating convolutonal layers increased accuracy a lot\n",
    "- Hyperparameter tuning was performed, but a lot of the parameters didn't change\n",
    "- Could run for longer, or look at all images in the dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
